{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql  as pyspark_sql\n",
    "import pyspark.sql.types as pyspark_types\n",
    "import pyspark.sql.functions  as pyspark_functions\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pandas import isnull\n",
    "from numpy import count_nonzero\n",
    "from pyspark.sql.functions import col, count, isnan, when, coalesce, lag, lead, sum\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the session\n",
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "\n",
    "# create the context\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark_sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = spark.read.csv(\"dataset/col_mat_nuw_output.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0.00019698343957810148: double (nullable = true)\n",
      " |-- Colombo Proper: string (nullable = true)\n",
      " |-- 2019-01-01: date (nullable = true)\n",
      " |-- 2019-01-02: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------+----------+----------+\n",
      "|0.00019698343957810148|Colombo Proper|2019-01-01|2019-01-02|\n",
      "+----------------------+--------------+----------+----------+\n",
      "|  2.625522171968594...|Colombo Proper|2019-01-02|2019-01-03|\n",
      "|  9.852118897938794E-5|Colombo Proper|2019-01-03|2019-01-04|\n",
      "|  2.099320518114242E-4|Colombo Proper|2019-01-04|2019-01-05|\n",
      "|  1.785337298892930...|Colombo Proper|2019-01-05|2019-01-06|\n",
      "|  1.082296700235670...|Colombo Proper|2019-01-06|2019-01-07|\n",
      "|  3.926829280477309...|Colombo Proper|2019-01-07|2019-01-08|\n",
      "|  9.153156350685351E-5|Colombo Proper|2019-01-08|2019-01-09|\n",
      "|  1.205978992853015...|Colombo Proper|2019-01-09|2019-01-10|\n",
      "|  1.297723562983258...|Colombo Proper|2019-01-10|2019-01-11|\n",
      "|  2.239188166801278...|Colombo Proper|2019-01-11|2019-01-12|\n",
      "|  1.569418094178759...|Colombo Proper|2019-01-12|2019-01-13|\n",
      "|                  NULL|Colombo Proper|2019-01-13|2019-01-14|\n",
      "|  1.336291906862603...|Colombo Proper|2019-01-14|2019-01-15|\n",
      "|  6.374417842690063E-5|Colombo Proper|2019-01-15|2019-01-16|\n",
      "|  1.181062250815020...|Colombo Proper|2019-01-16|2019-01-17|\n",
      "|  2.472555222423037...|Colombo Proper|2019-01-17|2019-01-18|\n",
      "|  3.667525352047757E-5|Colombo Proper|2019-01-18|2019-01-19|\n",
      "|  4.057500868150313E-4|Colombo Proper|2019-01-19|2019-01-20|\n",
      "|  1.687856216479722...|Colombo Proper|2019-01-20|2019-01-21|\n",
      "|  3.881549328739672...|Colombo Proper|2019-01-21|2019-01-22|\n",
      "+----------------------+--------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------+----------+\n",
      "|        HCHO reading|      Location|Current Date| Next Date|\n",
      "+--------------------+--------------+------------+----------+\n",
      "|2.625522171968594...|Colombo Proper|  2019-01-02|2019-01-03|\n",
      "|9.852118897938794E-5|Colombo Proper|  2019-01-03|2019-01-04|\n",
      "|2.099320518114242E-4|Colombo Proper|  2019-01-04|2019-01-05|\n",
      "|1.785337298892930...|Colombo Proper|  2019-01-05|2019-01-06|\n",
      "|1.082296700235670...|Colombo Proper|  2019-01-06|2019-01-07|\n",
      "|3.926829280477309...|Colombo Proper|  2019-01-07|2019-01-08|\n",
      "|9.153156350685351E-5|Colombo Proper|  2019-01-08|2019-01-09|\n",
      "|1.205978992853015...|Colombo Proper|  2019-01-09|2019-01-10|\n",
      "|1.297723562983258...|Colombo Proper|  2019-01-10|2019-01-11|\n",
      "|2.239188166801278...|Colombo Proper|  2019-01-11|2019-01-12|\n",
      "|1.569418094178759...|Colombo Proper|  2019-01-12|2019-01-13|\n",
      "|                NULL|Colombo Proper|  2019-01-13|2019-01-14|\n",
      "|1.336291906862603...|Colombo Proper|  2019-01-14|2019-01-15|\n",
      "|6.374417842690063E-5|Colombo Proper|  2019-01-15|2019-01-16|\n",
      "|1.181062250815020...|Colombo Proper|  2019-01-16|2019-01-17|\n",
      "|2.472555222423037...|Colombo Proper|  2019-01-17|2019-01-18|\n",
      "|3.667525352047757E-5|Colombo Proper|  2019-01-18|2019-01-19|\n",
      "|4.057500868150313E-4|Colombo Proper|  2019-01-19|2019-01-20|\n",
      "|1.687856216479722...|Colombo Proper|  2019-01-20|2019-01-21|\n",
      "|3.881549328739672...|Colombo Proper|  2019-01-21|2019-01-22|\n",
      "+--------------------+--------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_names = ['HCHO reading', 'Location', 'Current Date', 'Next Date']\n",
    "\n",
    "# Rename columns using withColumnRenamed()\n",
    "for i, new_name in enumerate(column_names):\n",
    "    data = data.withColumnRenamed(data.columns[i], new_name)\n",
    "\n",
    "# Display the DataFrame\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|           Location|\n",
      "+-------------------+\n",
      "|   Deniyaya, Matara|\n",
      "|     Colombo Proper|\n",
      "|Nuwara Eliya Proper|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check unique values of cities\n",
    "unique_cities = data.select(\"Location\").distinct()\n",
    "unique_cities.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|        HCHO reading|\n",
      "+-------+--------------------+\n",
      "|  count|                3058|\n",
      "|   mean|1.200178195763001...|\n",
      "| stddev|1.009287188756533...|\n",
      "|    min|-2.59296176552668...|\n",
      "|    max|8.997101837438971E-4|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe the 'HCHO reading' column\n",
    "data.select('HCHO reading').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+---------+\n",
      "|HCHO reading|Location|Current Date|Next Date|\n",
      "+------------+--------+------------+---------+\n",
      "|        2419|       0|           0|        0|\n",
      "+------------+--------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the DataFrame\n",
    "data.select([count(when(col(c).isNull(), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a counter for null values\n",
    "null_count = data.filter(col(\"HCHO Reading\").isNull()).count()\n",
    "\n",
    "# Continue the process until there are no nulls left\n",
    "while null_count > 0:\n",
    "    # Define the window specifications\n",
    "    backward_windowSpec = Window.orderBy(\"Current Date\")\n",
    "    forward_windowSpec = Window.orderBy(\"Current Date\")\n",
    "    \n",
    "    # Use lag to carry the last observation forward\n",
    "    previous_value = lag(\"HCHO Reading\", 1).over(backward_windowSpec)\n",
    "    data = data.withColumn(\"HCHO Reading\", coalesce(\"HCHO Reading\", previous_value))\n",
    "    \n",
    "    # Use lead to carry the next observation backward\n",
    "    next_value = lead(\"HCHO Reading\", 1).over(forward_windowSpec)\n",
    "    data = data.withColumn(\"HCHO Reading\", coalesce(\"HCHO Reading\", next_value))\n",
    "    \n",
    "    # Update the null count\n",
    "    null_count = data.filter(col(\"HCHO Reading\").isNull()).count()\n",
    "\n",
    "# cmn_data now has the nulls filled using a combination of LOCF and NOCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------------+----------+\n",
      "|        HCHO Reading|           Location|Current Date| Next Date|\n",
      "+--------------------+-------------------+------------+----------+\n",
      "|2.625522171968594...|   Deniyaya, Matara|  2019-01-01|2019-01-02|\n",
      "|2.625522171968594...|Nuwara Eliya Proper|  2019-01-01|2019-01-02|\n",
      "|2.625522171968594...|     Colombo Proper|  2019-01-02|2019-01-03|\n",
      "|5.803530712000793E-6|   Deniyaya, Matara|  2019-01-02|2019-01-03|\n",
      "|5.803530712000793E-6|Nuwara Eliya Proper|  2019-01-02|2019-01-03|\n",
      "|9.852118897938794E-5|     Colombo Proper|  2019-01-03|2019-01-04|\n",
      "|2.362357772653922...|   Deniyaya, Matara|  2019-01-03|2019-01-04|\n",
      "|1.908293886956784...|Nuwara Eliya Proper|  2019-01-03|2019-01-04|\n",
      "|2.099320518114242E-4|     Colombo Proper|  2019-01-04|2019-01-05|\n",
      "|6.437245753953118E-5|   Deniyaya, Matara|  2019-01-04|2019-01-05|\n",
      "|5.097625917127737...|Nuwara Eliya Proper|  2019-01-04|2019-01-05|\n",
      "|1.785337298892930...|     Colombo Proper|  2019-01-05|2019-01-06|\n",
      "|5.349707092885017E-5|   Deniyaya, Matara|  2019-01-05|2019-01-06|\n",
      "|6.456645496655256E-5|Nuwara Eliya Proper|  2019-01-05|2019-01-06|\n",
      "|1.082296700235670...|     Colombo Proper|  2019-01-06|2019-01-07|\n",
      "|1.315594859189690...|   Deniyaya, Matara|  2019-01-06|2019-01-07|\n",
      "|8.982348709518115E-5|Nuwara Eliya Proper|  2019-01-06|2019-01-07|\n",
      "|3.926829280477309...|     Colombo Proper|  2019-01-07|2019-01-08|\n",
      "|6.269859896976347E-5|   Deniyaya, Matara|  2019-01-07|2019-01-08|\n",
      "|4.097797651418246E-5|Nuwara Eliya Proper|  2019-01-07|2019-01-08|\n",
      "+--------------------+-------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+---------+\n",
      "|HCHO Reading|Location|Current Date|Next Date|\n",
      "+------------+--------+------------+---------+\n",
      "|           0|       0|           0|        0|\n",
      "+------------+--------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null values in each column\n",
    "null_counts = data.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in data.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DataFrame: 5477\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the DataFrame\n",
    "data_count = data.count()\n",
    "\n",
    "# Show the length of the DataFrame\n",
    "print(\"Length of DataFrame:\", data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------------+----------+\n",
      "|        HCHO Reading|           Location|Current Date| Next Date|\n",
      "+--------------------+-------------------+------------+----------+\n",
      "|2.625522171968594...|   Deniyaya, Matara|  2019-01-01|2019-01-02|\n",
      "|2.625522171968594...|Nuwara Eliya Proper|  2019-01-01|2019-01-02|\n",
      "|2.625522171968594...|     Colombo Proper|  2019-01-02|2019-01-03|\n",
      "|5.803530712000793E-6|   Deniyaya, Matara|  2019-01-02|2019-01-03|\n",
      "|5.803530712000793E-6|Nuwara Eliya Proper|  2019-01-02|2019-01-03|\n",
      "|9.852118897938794E-5|     Colombo Proper|  2019-01-03|2019-01-04|\n",
      "|2.362357772653922...|   Deniyaya, Matara|  2019-01-03|2019-01-04|\n",
      "|1.908293886956784...|Nuwara Eliya Proper|  2019-01-03|2019-01-04|\n",
      "|2.099320518114242E-4|     Colombo Proper|  2019-01-04|2019-01-05|\n",
      "|6.437245753953118E-5|   Deniyaya, Matara|  2019-01-04|2019-01-05|\n",
      "|5.097625917127737...|Nuwara Eliya Proper|  2019-01-04|2019-01-05|\n",
      "|1.785337298892930...|     Colombo Proper|  2019-01-05|2019-01-06|\n",
      "|5.349707092885017E-5|   Deniyaya, Matara|  2019-01-05|2019-01-06|\n",
      "|6.456645496655256E-5|Nuwara Eliya Proper|  2019-01-05|2019-01-06|\n",
      "|1.082296700235670...|     Colombo Proper|  2019-01-06|2019-01-07|\n",
      "|1.315594859189690...|   Deniyaya, Matara|  2019-01-06|2019-01-07|\n",
      "|8.982348709518115E-5|Nuwara Eliya Proper|  2019-01-06|2019-01-07|\n",
      "|3.926829280477309...|     Colombo Proper|  2019-01-07|2019-01-08|\n",
      "|6.269859896976347E-5|   Deniyaya, Matara|  2019-01-07|2019-01-08|\n",
      "|4.097797651418246E-5|Nuwara Eliya Proper|  2019-01-07|2019-01-08|\n",
      "+--------------------+-------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates from the DataFrame\n",
    "data_no_duplicates = data.dropDuplicates()\n",
    "\n",
    "# Show the first few rows of the DataFrame after dropping duplicates\n",
    "data_no_duplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DataFrame: 5477\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the DataFrame\n",
    "data_count = data.count()\n",
    "\n",
    "# Show the length of the DataFrame\n",
    "print(\"Length of DataFrame:\", data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HCHO Reading             Location Current Date   Next Date\n",
      "0         0.000263     Deniyaya, Matara   2019-01-01  2019-01-02\n",
      "1         0.000263  Nuwara Eliya Proper   2019-01-01  2019-01-02\n",
      "2         0.000263       Colombo Proper   2019-01-02  2019-01-03\n",
      "3         0.000006     Deniyaya, Matara   2019-01-02  2019-01-03\n",
      "4         0.000006  Nuwara Eliya Proper   2019-01-02  2019-01-03\n",
      "...            ...                  ...          ...         ...\n",
      "5472      0.000080       Colombo Proper   2023-12-31  2024-01-01\n",
      "5473      0.000080     Deniyaya, Matara   2023-12-31  2024-01-01\n",
      "5474      0.000080  Nuwara Eliya Proper   2023-12-31  2024-01-01\n",
      "5475      0.000254       Colombo Proper   2022-03-07  2022-03-08\n",
      "5476      0.000029     Deniyaya, Matara   2022-07-10  2022-07-11\n",
      "\n",
      "[5477 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert PySpark DataFrame to Pandas DataFrame\n",
    "pandas_df = data_no_duplicates.toPandas()\n",
    "\n",
    "# Show the Pandas DataFrame\n",
    "print(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `column_name` cannot be resolved. Did you mean one of the following? [`HCHO Reading`, `Location`, `Current Date`, `Next Date`].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m stats\n\u001b[0;32m      3\u001b[0m \u001b[39m# Calculate Z-scores\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m z_scores \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39mzscore(data[\u001b[39m'\u001b[39;49m\u001b[39mcolumn_name\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      6\u001b[0m \u001b[39m# Define threshold for outlier detection (e.g., Z-score > 3 or < -3)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:3078\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   3006\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the column as a :class:`Column`.\u001b[39;00m\n\u001b[0;32m   3007\u001b[0m \n\u001b[0;32m   3008\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3075\u001b[0m \u001b[39m+---+----+\u001b[39;00m\n\u001b[0;32m   3076\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3077\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 3078\u001b[0m     jc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mapply(item)\n\u001b[0;32m   3079\u001b[0m     \u001b[39mreturn\u001b[39;00m Column(jc)\n\u001b[0;32m   3080\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, Column):\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `column_name` cannot be resolved. Did you mean one of the following? [`HCHO Reading`, `Location`, `Current Date`, `Next Date`]."
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = stats.zscore(data['column_name'])\n",
    "\n",
    "# Define threshold for outlier detection (e.g., Z-score > 3 or < -3)\n",
    "threshold = 3\n",
    "\n",
    "# Identify outliers\n",
    "outliers = data[np.abs(z_scores) > threshold]\n",
    "\n",
    "# Optionally, remove outliers from the dataset\n",
    "# df = df[np.abs(z_scores) <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
